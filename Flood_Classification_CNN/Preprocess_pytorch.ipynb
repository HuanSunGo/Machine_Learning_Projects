{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocess - pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><img width=\"50%\" src=\"https://aimodelsharecontent.s3.amazonaws.com/aimodshare_banner.jpg\" /></p>\n",
        "\n",
        "# Climate Change Satellite Image Classification Competition Model Submission Guide - PyTorch\n",
        "\n",
        "---\n",
        "**About the Original Data:**<br>\n",
        "*Data and Description accessed from [Tensorflow](https://www.tensorflow.org/datasets/catalog/bigearthnet)* <br>\n",
        "The BigEarthNet is a new large-scale Sentinel-2 benchmark archive, consisting of 590,326 Sentinel-2 image patches. The image patch size on the ground is 1.2 x 1.2 km with variable image size depending on the channel resolution. This is a multi-label dataset with 43 imbalanced labels, which has been simplified to single labels with 3 categories for the purposes of this competition.\n",
        "\n",
        "To construct the BigEarthNet, 125 Sentinel-2 tiles acquired between June 2017 and May 2018 over the 10 countries (Austria, Belgium, Finland, Ireland, Kosovo, Lithuania, Luxembourg, Portugal, Serbia, Switzerland) of Europe were initially selected. All the tiles were atmospherically corrected by the Sentinel-2 Level 2A product generation and formatting tool (sen2cor). Then, they were divided into 590,326 non-overlapping image patches. Each image patch was annotated by the multiple land-cover classes (i.e., multi-labels) that were provided from the CORINE Land Cover database of the year 2018 (CLC 2018).\n",
        "\n",
        "Bands and pixel resolution in meters:\n",
        "\n",
        "    B01: Coastal aerosol; 60m\n",
        "    B02: Blue; 10m\n",
        "    B03: Green; 10m\n",
        "    B04: Red; 10m\n",
        "    B05: Vegetation red edge; 20m\n",
        "    B06: Vegetation red edge; 20m\n",
        "    B07: Vegetation red edge; 20m\n",
        "    B08: NIR; 10m\n",
        "    B09: Water vapor; 60m\n",
        "    B11: SWIR; 20m\n",
        "    B12: SWIR; 20m\n",
        "    B8A: Narrow NIR; 20m\n",
        "\n",
        "License: Community Data License Agreement - Permissive, Version 1.0.\"\n",
        "\n",
        "**Competition Data Specifics:**<br>\n",
        "For the purpose of this competition, the original BigEarthNet dataset has been simplified to 20,000 images (15,000 training images and 5,000 test images) with 3 categories: \"forest\", \"nonforest\", and \"snow_shadow_cloud\", which contains images of snow and clouds. <br>\n",
        "Each \"image\" is a folder with 12 satellite image layers, each of which pics up on different features. The example preprocessor uses just three layers: B02, B03, and B04, which contain the standard RGB layers used in ML models. However, you are free to use any combination of the satellite image layers. \n",
        "\n",
        "**Data Source:**<br>\n",
        "Sumbul, G, Charfuelan, M, Demir, B and Markl, V. (2019). BigEarthNet: A Large-Scale Benchmark Archive For Remote Sensing Image Understanding. *Computing Research Repository (CoRR), abs/1902.06148.* https://www.tensorflow.org/datasets/catalog/bigearthnet\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uV3KTobAN0s6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "---\n",
        "\n",
        "Let's share our models to a centralized leaderboard, so that we can collaborate and learn from the model experimentation process...\n",
        "\n",
        "**Instructions:**\n",
        "1.   Get data in and set up X_train / X_test / y_train\n",
        "2.   Preprocess data / Write and Save Preprocessor function\n",
        "3. Fit model on preprocessed data and save preprocessor function and model \n",
        "4. Generate predictions from X_test data and submit model to competition\n",
        "5. Repeat submission process to improve place on leaderboard\n",
        "\n"
      ],
      "metadata": {
        "id": "VvAhl6E3N-JN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load Data"
      ],
      "metadata": {
        "id": "iR_a3al2OJgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install aimodelshare library\n",
        "! pip install aimodelshare-nightly"
      ],
      "metadata": {
        "id": "Zd901sm6OJ6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Original preprocess notebook]('https://colab.research.google.com/drive/1K7Cpg4oFdDrEV09CFODfY9Qq1Ao1o0iW')"
      ],
      "metadata": {
        "id": "babPCIpPRQ-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get competition data - May take a couple minutes due to size of data set\n",
        "from aimodelshare import download_data\n",
        "#download_data('public.ecr.aws/y2e2a1d6/climate_competition_data-repository:latest') "
      ],
      "metadata": {
        "id": "YDB4AcAyOLNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip Data - May take a couple minutes due to size of data set\n",
        "import zipfile\n",
        "#with zipfile.ZipFile('climate_competition_data/climate_competition_data.zip', 'r') as zip_ref:\n",
        "    #zip_ref.extractall('competition_data')"
      ],
      "metadata": {
        "id": "fcMtZUTzONsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.   Preprocess data / Write and Save Preprocessor function\n"
      ],
      "metadata": {
        "id": "j_BrCD_DORfE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3gLdb5k5vDk"
      },
      "source": [
        "### **Write a Preprocessor Function**\n",
        "\n",
        "\n",
        "> ###   Preprocessor functions are used to preprocess data into the precise data your model requires to generate predictions.  \n",
        "\n",
        "*  *Preprocessor functions should always be named \"preprocessor\".*\n",
        "*  *You can use any Python library in a preprocessor function, but all libraries should be imported inside your preprocessor function.*  \n",
        "*  *For image prediction models users should minimally include function inputs for an image filepath and values to reshape the image height and width.*  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up for data preprocessing\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "_x-u9pp4OiqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is a pre-designed preprocessor, but you could also build your own to prepare the data differently\n",
        "\n",
        "def preprocessor(imageband_directory):\n",
        "        \"\"\"\n",
        "        This function preprocesses reads in images, resizes them to a fixed shape and\n",
        "        min/max transforms them before converting feature values to float32 numeric values\n",
        "        required by onnx files.\n",
        "        \n",
        "        params:\n",
        "            imageband_directory\n",
        "                path to folder with 13 satellite image bands\n",
        "                      \n",
        "        returns:\n",
        "            X\n",
        "                numpy array of preprocessed image data\n",
        "                  \n",
        "        \"\"\"\n",
        "           \n",
        "        import PIL\n",
        "        import os\n",
        "        import numpy as np\n",
        "        import tensorflow_datasets as tfds\n",
        "\n",
        "        def _load_tif(data):\n",
        "            \"\"\"Loads TIF file and returns as float32 numpy array.\"\"\"\n",
        "            img=tfds.core.lazy_imports.PIL_Image.open(data)\n",
        "            img = np.array(img.getdata()).reshape(img.size).astype(np.float32)\n",
        "            return img\n",
        "\n",
        "        image_list = []\n",
        "        filelist1=os.listdir(imageband_directory)\n",
        "        for fpath in filelist1:\n",
        "          fullpath=imageband_directory+\"/\"+fpath\n",
        "          if fullpath.endswith(('B02.tif','B03.tif','B04.tif')):\n",
        "              imgarray=_load_tif(imageband_directory+\"/\"+fpath)\n",
        "              image_list.append(imgarray)\n",
        "\n",
        "        X = np.stack(image_list,axis=2)   # to get (height,width,3)\n",
        "\n",
        "        X = np.expand_dims(X, axis=0) # Expand dims to add \"1\" to object shape [1, h, w, channels] for keras model.\n",
        "        X = np.array(X, dtype=np.float32) # Final shape for onnx runtime.\n",
        "        X=X/18581 # min max transform to max value\n",
        "        return X"
      ],
      "metadata": {
        "id": "TROpuiNqOkHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create complete list of file names\n",
        "forestfilenames=[\"competition_data/trainingdata/forest/\"+x for x in os.listdir(\"competition_data/trainingdata/forest\")]\n",
        "nonforestfilenames=[\"competition_data/trainingdata/nonforest/\"+x for x in os.listdir(\"competition_data/trainingdata/nonforest\")]\n",
        "otherfilenames=[\"competition_data/trainingdata/other/\"+x for x in os.listdir(\"competition_data/trainingdata/other\")]\n",
        "\n",
        "filenames=forestfilenames+nonforestfilenames+otherfilenames\n",
        "\n",
        "#preprocess rbg images into 120,120,3 numpy ndarray\n",
        "preprocessed_image_data=[]\n",
        "for i in filenames:\n",
        "  try:\n",
        "    preprocessed_image_data.append(preprocessor(i))\n",
        "  except:\n",
        "    pass  \n",
        "  "
      ],
      "metadata": {
        "id": "g1nQKtWeOqe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up y data\n",
        "from itertools import repeat\n",
        "forest=repeat(\"forest\",5000)\n",
        "nonforest=repeat(\"nonforest\",5000)\n",
        "other=repeat(\"snow_shadow_cloud\",5000)\n",
        "ylist=list(forest)+list(nonforest)+list(other)"
      ],
      "metadata": {
        "id": "CUNMzqjdOr7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle X and y data\n",
        "from sklearn.utils import shuffle\n",
        "X, y = shuffle(preprocessed_image_data, ylist, random_state=0)"
      ],
      "metadata": {
        "id": "y42kU5txOtbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X =np.vstack(X) # convert X from list to array"
      ],
      "metadata": {
        "id": "JpwMX1gzOvBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0mpnM4ROwki",
        "outputId": "69d953ae-9eea-447d-a18c-5be263fc7f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000, 120, 120, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get numerical representation of y labels\n",
        "import pandas as pd\n",
        "y_labels_num = pd.DataFrame(y)[0].map({'forest': 0, 'nonforest': 1, 'snow_shadow_cloud': 2}) \n",
        "\n",
        "y_labels_num = list(y_labels_num)"
      ],
      "metadata": {
        "id": "d57yWx8JOTsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate 20% of Data for validation\n",
        "X_train = X[0:12000]\n",
        "X_val = X[12001:15000]\n",
        "y_train = y_labels_num[0:12000]\n",
        "y_val = y_labels_num[12001:15000]"
      ],
      "metadata": {
        "id": "fBmRg-1VMthQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3bkrYdaM6A3",
        "outputId": "1da3deff-7d9d-4bad-da08-400eae7b12d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000, 120, 120, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJlhd6jvns0b"
      },
      "source": [
        "##3. Fit model on preprocessed data and save preprocessor function and model "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "eK9Ogef_URfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prepare Data** for Pytorch"
      ],
      "metadata": {
        "id": "yJg6iCCv-Bvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPSb5EjEaW8H",
        "outputId": "9db2d537-001b-470d-822d-45f398b55b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare datasets for pytorch dataloader\n",
        "tensor_X_train = torch.Tensor(X_train)\n",
        "tensor_y_train = torch.tensor(y_train, dtype=torch.long) \n",
        "train_ds = TensorDataset(tensor_X_train, tensor_y_train) \n",
        "\n",
        "tensor_X_test = torch.Tensor(X_val) \n",
        "tensor_y_test = torch.tensor(y_val, dtype=torch.long) \n",
        "test_ds = TensorDataset(tensor_X_test, tensor_y_test)"
      ],
      "metadata": {
        "id": "COE6LNtQPrS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up dataloaders\n",
        "batch_size = 50\n",
        "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "jtvH9nX6AFxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SoTp-92T6CD",
        "outputId": "a4a951ab-274e-4929-e442-9165ff952b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([50, 120, 120, 3])\n",
            "Shape of y: torch.Size([50]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP7ZIVKe3luZ"
      },
      "source": [
        "### Pytorch **Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define pytorch model\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(120*120*3, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 5)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5hOI5SpUl3s",
        "outputId": "a7662949-ffb5-4e4d-ef1d-4139d1ad31aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=43200, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=5, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "95bsqAReUq3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define training function\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "CoeGKnPyUx__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define testing function\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "IrtrW6WqU1Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "L4vGb5T4U5e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZGlu5PMWbNO"
      },
      "source": [
        "#### Save preprocessor function to \"preprocessor.zip\" file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh_vkwblXx7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b649069-07c3-40e2-a390-300148d40d6e"
      },
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "can't pickle module objects\n",
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdQOeF2J3PCv"
      },
      "source": [
        "#### Save model to local \".onnx\" file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8fgi8f6qkbk"
      },
      "source": [
        "# Save pytorch model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "example_input = torch.randn(1, 3, 120, 120, requires_grad=True)\n",
        "\n",
        "onnx_model = model_to_onnx(model, framework='pytorch',\n",
        "                           model_input=example_input,\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Generate predictions from X_test data and submit model to competition"
      ],
      "metadata": {
        "id": "3h62QWk_QvVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import and preprocess X_test images in correct order...\n",
        "# ...for leaderboard prediction submissions\n",
        "filenumbers=[str(x) for x in range(1, 5001)]\n",
        "filenames=[\"competition_data/testdata/test/test\"+x for x in filenumbers]\n",
        "\n",
        "#preprocess rbg images into 120,120,3 numpy ndarray\n",
        "preprocessed_image_data=[]\n",
        "for i in filenames:\n",
        "  try:\n",
        "    preprocessed_image_data.append(preprocessor(i))\n",
        "  except:\n",
        "    pass  "
      ],
      "metadata": {
        "id": "-RBmiBbpQyb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_submissiondata=np.vstack(preprocessed_image_data) \n",
        "tensor_X_test_submissiondata = torch.Tensor(X_test_submissiondata) "
      ],
      "metadata": {
        "id": "t3peXFlLQ0OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set credentials using modelshare.org username/password\n",
        "\n",
        "from aimodelshare.aws import set_credentials\n",
        "\n",
        "# Note -- This is the unique rest api that powers this climate change image classification  Model Plaground\n",
        "# ... Update the apiurl if submitting to a new competition\n",
        "\n",
        "apiurl=\"https://srdmat3yhf.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
        "set_credentials(apiurl=apiurl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpI5yJV3Q0x7",
        "outputId": "74dfc3a0-d4a1-4c59-ad64-4f2e26710e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Modelshare Username:··········\n",
            "AI Modelshare Password:··········\n",
            "AI Model Share login credentials set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate Competition\n",
        "\n",
        "mycompetition= ai.Competition(apiurl)"
      ],
      "metadata": {
        "id": "YscQsC_eQ3vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model 1: \n",
        "import pandas \n",
        "\n",
        "#-- Generate predicted y values (Model 1)\n",
        "#Note: Keras predict returns the predicted column index location for classification models\n",
        "prediction_column_index=model(tensor_X_test_submissiondata).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [['forest', 'nonforest', 'snow_shadow_cloud'][i] for i in prediction_column_index]"
      ],
      "metadata": {
        "id": "tMnQlE_KQ5Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9-tNbKKPkCz",
        "outputId": "17cebe00-db43-4d4d-b653-11f88a3f9f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 7\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:1535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get leaderboard to explore current best model architectures\n",
        "\n",
        "# Get raw data in pandas data frame\n",
        "data = mycompetition.get_leaderboard()\n",
        "\n",
        "# Stylize leaderboard data\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "RuLYQNKLROva",
        "outputId": "4ad0becf-bbe9-4e04-dc0e-07ac217977e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_927c2_row0_col0 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#f5f8d6 54.3%, transparent 54.3%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row0_col1 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#c778c8 46.1%, transparent 46.1%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row0_col2 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#ff4971 44.4%, transparent 44.4%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row0_col3 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#aadbaa 48.1%, transparent 48.1%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row0_col4, #T_927c2_row0_col5, #T_927c2_row0_col6, #T_927c2_row0_col7, #T_927c2_row0_col8, #T_927c2_row0_col9, #T_927c2_row0_col10, #T_927c2_row0_col11, #T_927c2_row0_col12, #T_927c2_row0_col13, #T_927c2_row0_col14, #T_927c2_row0_col15, #T_927c2_row0_col16, #T_927c2_row0_col17, #T_927c2_row0_col18, #T_927c2_row0_col19, #T_927c2_row0_col20, #T_927c2_row0_col21, #T_927c2_row1_col4, #T_927c2_row1_col5, #T_927c2_row1_col6, #T_927c2_row1_col7, #T_927c2_row1_col8, #T_927c2_row1_col9, #T_927c2_row1_col10, #T_927c2_row1_col11, #T_927c2_row1_col12, #T_927c2_row1_col13, #T_927c2_row1_col14, #T_927c2_row1_col15, #T_927c2_row1_col16, #T_927c2_row1_col17, #T_927c2_row1_col18, #T_927c2_row1_col19, #T_927c2_row1_col20, #T_927c2_row1_col21, #T_927c2_row2_col4, #T_927c2_row2_col5, #T_927c2_row2_col6, #T_927c2_row2_col7, #T_927c2_row2_col8, #T_927c2_row2_col9, #T_927c2_row2_col10, #T_927c2_row2_col11, #T_927c2_row2_col12, #T_927c2_row2_col13, #T_927c2_row2_col14, #T_927c2_row2_col15, #T_927c2_row2_col16, #T_927c2_row2_col17, #T_927c2_row2_col18, #T_927c2_row2_col19, #T_927c2_row2_col20, #T_927c2_row2_col21, #T_927c2_row3_col4, #T_927c2_row3_col5, #T_927c2_row3_col6, #T_927c2_row3_col7, #T_927c2_row3_col8, #T_927c2_row3_col9, #T_927c2_row3_col10, #T_927c2_row3_col11, #T_927c2_row3_col12, #T_927c2_row3_col13, #T_927c2_row3_col14, #T_927c2_row3_col15, #T_927c2_row3_col16, #T_927c2_row3_col17, #T_927c2_row3_col18, #T_927c2_row3_col19, #T_927c2_row3_col20, #T_927c2_row3_col21, #T_927c2_row4_col4, #T_927c2_row4_col5, #T_927c2_row4_col6, #T_927c2_row4_col7, #T_927c2_row4_col8, #T_927c2_row4_col9, #T_927c2_row4_col10, #T_927c2_row4_col11, #T_927c2_row4_col12, #T_927c2_row4_col13, #T_927c2_row4_col14, #T_927c2_row4_col15, #T_927c2_row4_col16, #T_927c2_row4_col17, #T_927c2_row4_col18, #T_927c2_row4_col19, #T_927c2_row4_col20, #T_927c2_row4_col21 {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_927c2_row1_col0 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#f5f8d6 56.9%, transparent 56.9%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row1_col1 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#c778c8 45.4%, transparent 45.4%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row1_col2 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#ff4971 42.3%, transparent 42.3%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row1_col3 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#aadbaa 49.1%, transparent 49.1%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row2_col0 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#f5f8d6 45.6%, transparent 45.6%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row2_col1, #T_927c2_row3_col1 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#c778c8 43.4%, transparent 43.4%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row2_col2 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#ff4971 46.7%, transparent 46.7%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row2_col3 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#aadbaa 40.5%, transparent 40.5%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row3_col0 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#f5f8d6 40.1%, transparent 40.1%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row3_col2 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#ff4971 44.8%, transparent 44.8%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row3_col3 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#aadbaa 47.8%, transparent 47.8%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row4_col0 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#f5f8d6 34.9%, transparent 34.9%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row4_col1 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#c778c8 32.5%, transparent 32.5%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row4_col2 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#ff4971 34.9%, transparent 34.9%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "#T_927c2_row4_col3 {\n",
              "  text-align: center;\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#aadbaa 35.2%, transparent 35.2%);\n",
              "  color: #251e1b;\n",
              "  font-size: 12px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_927c2_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >accuracy</th>\n",
              "      <th class=\"col_heading level0 col1\" >f1_score</th>\n",
              "      <th class=\"col_heading level0 col2\" >precision</th>\n",
              "      <th class=\"col_heading level0 col3\" >recall</th>\n",
              "      <th class=\"col_heading level0 col4\" >ml_framework</th>\n",
              "      <th class=\"col_heading level0 col5\" >deep_learning</th>\n",
              "      <th class=\"col_heading level0 col6\" >model_type</th>\n",
              "      <th class=\"col_heading level0 col7\" >depth</th>\n",
              "      <th class=\"col_heading level0 col8\" >num_params</th>\n",
              "      <th class=\"col_heading level0 col9\" >dropout_layers</th>\n",
              "      <th class=\"col_heading level0 col10\" >dense_layers</th>\n",
              "      <th class=\"col_heading level0 col11\" >flatten_layers</th>\n",
              "      <th class=\"col_heading level0 col12\" >conv2d_layers</th>\n",
              "      <th class=\"col_heading level0 col13\" >maxpooling2d_layers</th>\n",
              "      <th class=\"col_heading level0 col14\" >softmax_act</th>\n",
              "      <th class=\"col_heading level0 col15\" >relu_act</th>\n",
              "      <th class=\"col_heading level0 col16\" >loss</th>\n",
              "      <th class=\"col_heading level0 col17\" >optimizer</th>\n",
              "      <th class=\"col_heading level0 col18\" >model_config</th>\n",
              "      <th class=\"col_heading level0 col19\" >memory_size</th>\n",
              "      <th class=\"col_heading level0 col20\" >username</th>\n",
              "      <th class=\"col_heading level0 col21\" >version</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_927c2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_927c2_row0_col0\" class=\"data row0 col0\" >54.28%</td>\n",
              "      <td id=\"T_927c2_row0_col1\" class=\"data row0 col1\" >46.12%</td>\n",
              "      <td id=\"T_927c2_row0_col2\" class=\"data row0 col2\" >44.40%</td>\n",
              "      <td id=\"T_927c2_row0_col3\" class=\"data row0 col3\" >48.11%</td>\n",
              "      <td id=\"T_927c2_row0_col4\" class=\"data row0 col4\" >sklearn</td>\n",
              "      <td id=\"T_927c2_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col6\" class=\"data row0 col6\" >RandomForestClassifier</td>\n",
              "      <td id=\"T_927c2_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col16\" class=\"data row0 col16\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col18\" class=\"data row0 col18\" >{'bootstrap': True, 'ccp_alpha...</td>\n",
              "      <td id=\"T_927c2_row0_col19\" class=\"data row0 col19\" >nan</td>\n",
              "      <td id=\"T_927c2_row0_col20\" class=\"data row0 col20\" >AIModelShare</td>\n",
              "      <td id=\"T_927c2_row0_col21\" class=\"data row0 col21\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_927c2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_927c2_row1_col0\" class=\"data row1 col0\" >56.88%</td>\n",
              "      <td id=\"T_927c2_row1_col1\" class=\"data row1 col1\" >45.37%</td>\n",
              "      <td id=\"T_927c2_row1_col2\" class=\"data row1 col2\" >42.31%</td>\n",
              "      <td id=\"T_927c2_row1_col3\" class=\"data row1 col3\" >49.11%</td>\n",
              "      <td id=\"T_927c2_row1_col4\" class=\"data row1 col4\" >sklearn</td>\n",
              "      <td id=\"T_927c2_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col6\" class=\"data row1 col6\" >RandomForestClassifier</td>\n",
              "      <td id=\"T_927c2_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col16\" class=\"data row1 col16\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col18\" class=\"data row1 col18\" >{'bootstrap': True, 'ccp_alpha...</td>\n",
              "      <td id=\"T_927c2_row1_col19\" class=\"data row1 col19\" >nan</td>\n",
              "      <td id=\"T_927c2_row1_col20\" class=\"data row1 col20\" >AIModelShare</td>\n",
              "      <td id=\"T_927c2_row1_col21\" class=\"data row1 col21\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_927c2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_927c2_row2_col0\" class=\"data row2 col0\" >45.60%</td>\n",
              "      <td id=\"T_927c2_row2_col1\" class=\"data row2 col1\" >43.39%</td>\n",
              "      <td id=\"T_927c2_row2_col2\" class=\"data row2 col2\" >46.70%</td>\n",
              "      <td id=\"T_927c2_row2_col3\" class=\"data row2 col3\" >40.53%</td>\n",
              "      <td id=\"T_927c2_row2_col4\" class=\"data row2 col4\" >keras</td>\n",
              "      <td id=\"T_927c2_row2_col5\" class=\"data row2 col5\" >True</td>\n",
              "      <td id=\"T_927c2_row2_col6\" class=\"data row2 col6\" >Sequential</td>\n",
              "      <td id=\"T_927c2_row2_col7\" class=\"data row2 col7\" >8.000000</td>\n",
              "      <td id=\"T_927c2_row2_col8\" class=\"data row2 col8\" >1847811.000000</td>\n",
              "      <td id=\"T_927c2_row2_col9\" class=\"data row2 col9\" >2.000000</td>\n",
              "      <td id=\"T_927c2_row2_col10\" class=\"data row2 col10\" >2.000000</td>\n",
              "      <td id=\"T_927c2_row2_col11\" class=\"data row2 col11\" >1.000000</td>\n",
              "      <td id=\"T_927c2_row2_col12\" class=\"data row2 col12\" >2.000000</td>\n",
              "      <td id=\"T_927c2_row2_col13\" class=\"data row2 col13\" >1.000000</td>\n",
              "      <td id=\"T_927c2_row2_col14\" class=\"data row2 col14\" >1.000000</td>\n",
              "      <td id=\"T_927c2_row2_col15\" class=\"data row2 col15\" >3.000000</td>\n",
              "      <td id=\"T_927c2_row2_col16\" class=\"data row2 col16\" >str</td>\n",
              "      <td id=\"T_927c2_row2_col17\" class=\"data row2 col17\" >RMSprop</td>\n",
              "      <td id=\"T_927c2_row2_col18\" class=\"data row2 col18\" >{'name': 'sequential', 'layers...</td>\n",
              "      <td id=\"T_927c2_row2_col19\" class=\"data row2 col19\" >2114288.000000</td>\n",
              "      <td id=\"T_927c2_row2_col20\" class=\"data row2 col20\" >AIModelShare</td>\n",
              "      <td id=\"T_927c2_row2_col21\" class=\"data row2 col21\" >5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_927c2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_927c2_row3_col0\" class=\"data row3 col0\" >40.08%</td>\n",
              "      <td id=\"T_927c2_row3_col1\" class=\"data row3 col1\" >43.37%</td>\n",
              "      <td id=\"T_927c2_row3_col2\" class=\"data row3 col2\" >44.80%</td>\n",
              "      <td id=\"T_927c2_row3_col3\" class=\"data row3 col3\" >47.78%</td>\n",
              "      <td id=\"T_927c2_row3_col4\" class=\"data row3 col4\" >keras</td>\n",
              "      <td id=\"T_927c2_row3_col5\" class=\"data row3 col5\" >True</td>\n",
              "      <td id=\"T_927c2_row3_col6\" class=\"data row3 col6\" >Sequential</td>\n",
              "      <td id=\"T_927c2_row3_col7\" class=\"data row3 col7\" >8.000000</td>\n",
              "      <td id=\"T_927c2_row3_col8\" class=\"data row3 col8\" >1847811.000000</td>\n",
              "      <td id=\"T_927c2_row3_col9\" class=\"data row3 col9\" >2.000000</td>\n",
              "      <td id=\"T_927c2_row3_col10\" class=\"data row3 col10\" >2.000000</td>\n",
              "      <td id=\"T_927c2_row3_col11\" class=\"data row3 col11\" >1.000000</td>\n",
              "      <td id=\"T_927c2_row3_col12\" class=\"data row3 col12\" >2.000000</td>\n",
              "      <td id=\"T_927c2_row3_col13\" class=\"data row3 col13\" >1.000000</td>\n",
              "      <td id=\"T_927c2_row3_col14\" class=\"data row3 col14\" >1.000000</td>\n",
              "      <td id=\"T_927c2_row3_col15\" class=\"data row3 col15\" >3.000000</td>\n",
              "      <td id=\"T_927c2_row3_col16\" class=\"data row3 col16\" >str</td>\n",
              "      <td id=\"T_927c2_row3_col17\" class=\"data row3 col17\" >RMSprop</td>\n",
              "      <td id=\"T_927c2_row3_col18\" class=\"data row3 col18\" >{'name': 'sequential', 'layers...</td>\n",
              "      <td id=\"T_927c2_row3_col19\" class=\"data row3 col19\" >2233032.000000</td>\n",
              "      <td id=\"T_927c2_row3_col20\" class=\"data row3 col20\" >AIModelShare</td>\n",
              "      <td id=\"T_927c2_row3_col21\" class=\"data row3 col21\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_927c2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_927c2_row4_col0\" class=\"data row4 col0\" >34.88%</td>\n",
              "      <td id=\"T_927c2_row4_col1\" class=\"data row4 col1\" >32.55%</td>\n",
              "      <td id=\"T_927c2_row4_col2\" class=\"data row4 col2\" >34.93%</td>\n",
              "      <td id=\"T_927c2_row4_col3\" class=\"data row4 col3\" >35.20%</td>\n",
              "      <td id=\"T_927c2_row4_col4\" class=\"data row4 col4\" >unknown</td>\n",
              "      <td id=\"T_927c2_row4_col5\" class=\"data row4 col5\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col6\" class=\"data row4 col6\" >unknown</td>\n",
              "      <td id=\"T_927c2_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col8\" class=\"data row4 col8\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col9\" class=\"data row4 col9\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col10\" class=\"data row4 col10\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col16\" class=\"data row4 col16\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col18\" class=\"data row4 col18\" >None...</td>\n",
              "      <td id=\"T_927c2_row4_col19\" class=\"data row4 col19\" >nan</td>\n",
              "      <td id=\"T_927c2_row4_col20\" class=\"data row4 col20\" >AIModelShare</td>\n",
              "      <td id=\"T_927c2_row4_col21\" class=\"data row4 col21\" >4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fecac30c850>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Repeat submission process to improve place on leaderboard\n",
        "\n",
        "*Train and submit your own models using code modeled after what you see above.*"
      ],
      "metadata": {
        "id": "5--1dWeGRS4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It may also be useful to examine the architeture of models that perform particuarly well/poorly, or to compare models you've created with similar models submitted by others. Use the compare_models function in combination with the leaderboard to learn more about models that been previously submitted and potentially make decisiona about what you should do next."
      ],
      "metadata": {
        "id": "Dl52vYGFRVNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare two or more models\n",
        "data=mycompetition.compare_models([1, 5], verbose=1)\n",
        "mycompetition.stylize_compare(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "9AFTuYebRXgc",
        "outputId": "53a28df5-2ee2-4c67-8a6c-2c18bedf79e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_718a6_ caption {\n",
              "  color: black;\n",
              "  font-size: 18px;\n",
              "}\n",
              "#T_718a6_row0_col0, #T_718a6_row0_col3, #T_718a6_row1_col0, #T_718a6_row1_col3 {\n",
              "  background: #fdcdac;\n",
              "  color: black;\n",
              "  color: black;\n",
              "}\n",
              "#T_718a6_row0_col1, #T_718a6_row0_col2, #T_718a6_row0_col4, #T_718a6_row0_col5, #T_718a6_row1_col1, #T_718a6_row1_col2, #T_718a6_row1_col4, #T_718a6_row1_col5, #T_718a6_row2_col1, #T_718a6_row2_col2, #T_718a6_row2_col4, #T_718a6_row2_col5, #T_718a6_row3_col1, #T_718a6_row3_col2, #T_718a6_row3_col4, #T_718a6_row3_col5, #T_718a6_row4_col1, #T_718a6_row4_col2, #T_718a6_row4_col4, #T_718a6_row4_col5, #T_718a6_row5_col1, #T_718a6_row5_col2, #T_718a6_row5_col4, #T_718a6_row5_col5, #T_718a6_row6_col1, #T_718a6_row6_col2, #T_718a6_row6_col4, #T_718a6_row6_col5, #T_718a6_row7_col1, #T_718a6_row7_col2, #T_718a6_row7_col4, #T_718a6_row7_col5 {\n",
              "  background: white;\n",
              "  color: black;\n",
              "  color: black;\n",
              "}\n",
              "#T_718a6_row2_col0, #T_718a6_row2_col3 {\n",
              "  background: #f1e2cc;\n",
              "  color: black;\n",
              "  color: black;\n",
              "}\n",
              "#T_718a6_row3_col0, #T_718a6_row3_col3, #T_718a6_row6_col0, #T_718a6_row6_col3 {\n",
              "  background: #cbd5e8;\n",
              "  color: black;\n",
              "  color: black;\n",
              "}\n",
              "#T_718a6_row4_col0, #T_718a6_row4_col3 {\n",
              "  background: #e6f5c9;\n",
              "  color: black;\n",
              "  color: black;\n",
              "}\n",
              "#T_718a6_row5_col0, #T_718a6_row5_col3, #T_718a6_row7_col0, #T_718a6_row7_col3 {\n",
              "  background: #fff2ae;\n",
              "  color: black;\n",
              "  color: black;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_718a6_\">\n",
              "  <caption>Model type: Neural Network</caption>\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >Model_1_Layer</th>\n",
              "      <th class=\"col_heading level0 col1\" >Model_1_Shape</th>\n",
              "      <th class=\"col_heading level0 col2\" >Model_1_Params</th>\n",
              "      <th class=\"col_heading level0 col3\" >Model_5_Layer</th>\n",
              "      <th class=\"col_heading level0 col4\" >Model_5_Shape</th>\n",
              "      <th class=\"col_heading level0 col5\" >Model_5_Params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_718a6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_718a6_row0_col0\" class=\"data row0 col0\" >Conv2D</td>\n",
              "      <td id=\"T_718a6_row0_col1\" class=\"data row0 col1\" >[None, 120, 120, 32]</td>\n",
              "      <td id=\"T_718a6_row0_col2\" class=\"data row0 col2\" >416</td>\n",
              "      <td id=\"T_718a6_row0_col3\" class=\"data row0 col3\" >Conv2D</td>\n",
              "      <td id=\"T_718a6_row0_col4\" class=\"data row0 col4\" >[None, 120, 120, 32]</td>\n",
              "      <td id=\"T_718a6_row0_col5\" class=\"data row0 col5\" >416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_718a6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_718a6_row1_col0\" class=\"data row1 col0\" >Conv2D</td>\n",
              "      <td id=\"T_718a6_row1_col1\" class=\"data row1 col1\" >[None, 120, 120, 32]</td>\n",
              "      <td id=\"T_718a6_row1_col2\" class=\"data row1 col2\" >4128</td>\n",
              "      <td id=\"T_718a6_row1_col3\" class=\"data row1 col3\" >Conv2D</td>\n",
              "      <td id=\"T_718a6_row1_col4\" class=\"data row1 col4\" >[None, 120, 120, 32]</td>\n",
              "      <td id=\"T_718a6_row1_col5\" class=\"data row1 col5\" >4128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_718a6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_718a6_row2_col0\" class=\"data row2 col0\" >MaxPooling2D</td>\n",
              "      <td id=\"T_718a6_row2_col1\" class=\"data row2 col1\" >[None, 60, 60, 32]</td>\n",
              "      <td id=\"T_718a6_row2_col2\" class=\"data row2 col2\" >0</td>\n",
              "      <td id=\"T_718a6_row2_col3\" class=\"data row2 col3\" >MaxPooling2D</td>\n",
              "      <td id=\"T_718a6_row2_col4\" class=\"data row2 col4\" >[None, 60, 60, 32]</td>\n",
              "      <td id=\"T_718a6_row2_col5\" class=\"data row2 col5\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_718a6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_718a6_row3_col0\" class=\"data row3 col0\" >Dropout</td>\n",
              "      <td id=\"T_718a6_row3_col1\" class=\"data row3 col1\" >[None, 60, 60, 32]</td>\n",
              "      <td id=\"T_718a6_row3_col2\" class=\"data row3 col2\" >0</td>\n",
              "      <td id=\"T_718a6_row3_col3\" class=\"data row3 col3\" >Dropout</td>\n",
              "      <td id=\"T_718a6_row3_col4\" class=\"data row3 col4\" >[None, 60, 60, 32]</td>\n",
              "      <td id=\"T_718a6_row3_col5\" class=\"data row3 col5\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_718a6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_718a6_row4_col0\" class=\"data row4 col0\" >Flatten</td>\n",
              "      <td id=\"T_718a6_row4_col1\" class=\"data row4 col1\" >[None, 115200]</td>\n",
              "      <td id=\"T_718a6_row4_col2\" class=\"data row4 col2\" >0</td>\n",
              "      <td id=\"T_718a6_row4_col3\" class=\"data row4 col3\" >Flatten</td>\n",
              "      <td id=\"T_718a6_row4_col4\" class=\"data row4 col4\" >[None, 115200]</td>\n",
              "      <td id=\"T_718a6_row4_col5\" class=\"data row4 col5\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_718a6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_718a6_row5_col0\" class=\"data row5 col0\" >Dense</td>\n",
              "      <td id=\"T_718a6_row5_col1\" class=\"data row5 col1\" >[None, 16]</td>\n",
              "      <td id=\"T_718a6_row5_col2\" class=\"data row5 col2\" >1843216</td>\n",
              "      <td id=\"T_718a6_row5_col3\" class=\"data row5 col3\" >Dense</td>\n",
              "      <td id=\"T_718a6_row5_col4\" class=\"data row5 col4\" >[None, 16]</td>\n",
              "      <td id=\"T_718a6_row5_col5\" class=\"data row5 col5\" >1843216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_718a6_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_718a6_row6_col0\" class=\"data row6 col0\" >Dropout</td>\n",
              "      <td id=\"T_718a6_row6_col1\" class=\"data row6 col1\" >[None, 16]</td>\n",
              "      <td id=\"T_718a6_row6_col2\" class=\"data row6 col2\" >0</td>\n",
              "      <td id=\"T_718a6_row6_col3\" class=\"data row6 col3\" >Dropout</td>\n",
              "      <td id=\"T_718a6_row6_col4\" class=\"data row6 col4\" >[None, 16]</td>\n",
              "      <td id=\"T_718a6_row6_col5\" class=\"data row6 col5\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_718a6_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_718a6_row7_col0\" class=\"data row7 col0\" >Dense</td>\n",
              "      <td id=\"T_718a6_row7_col1\" class=\"data row7 col1\" >[None, 3]</td>\n",
              "      <td id=\"T_718a6_row7_col2\" class=\"data row7 col2\" >51</td>\n",
              "      <td id=\"T_718a6_row7_col3\" class=\"data row7 col3\" >Dense</td>\n",
              "      <td id=\"T_718a6_row7_col4\" class=\"data row7 col4\" >[None, 3]</td>\n",
              "      <td id=\"T_718a6_row7_col5\" class=\"data row7 col5\" >51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}